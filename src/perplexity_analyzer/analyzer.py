import torch
import math
from typing import List, Dict, Optional, Union
from tqdm import tqdm
from .models import ModelManager
from .utils import setup_logger, preprocess_text, split_into_sentences

logger = setup_logger(__name__)


class PerplexityAnalyzer:
    """í…ìŠ¤íŠ¸ì˜ Perplexityë¥¼ ë¶„ì„í•˜ì—¬ AI ìƒì„± ë¬¸ì¥ì„ íƒì§€í•˜ê³  ë¶„ë¥˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # ë¡œê·¸ perplexity ì„ê³„ê°’ (1.474 ì´í•˜ë©´ AI ìƒì„± ì˜ì‹¬)
    LOG_PPL_THRESHOLD = 1.474
    
    def __init__(self, model_name: str = 'gpt2', max_length: int = 512):
        """
        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ëª… ('gpt2', 'kogpt2' ë“±)
            max_length: í† í°í™”ì‹œ ìµœëŒ€ ê¸¸ì´
        """
        self.model_name = model_name
        self.max_length = max_length
        self.model_manager = ModelManager()
        self.model, self.tokenizer = self.model_manager.load_model(model_name)
        
        logger.info(f"PerplexityAnalyzer initialized with {model_name}")
    
    def calculate_log_perplexity(self, text: str) -> float:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ì˜ ë¡œê·¸ perplexity ê³„ì‚°"""
        if not text or not text.strip():
            return float('inf')
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        processed_text = preprocess_text(text)
        
        # í† í°í™”
        inputs = self.tokenizer(
            processed_text,
            return_tensors='pt',
            max_length=self.max_length,
            truncation=True,
            padding=True
        )
        
        inputs = {k: v.to(self.model_manager.device) for k, v in inputs.items()}
        
        try:
            with torch.no_grad():
                outputs = self.model(**inputs, labels=inputs['input_ids'])
                loss = outputs.loss
                log_perplexity = loss.item()  # ì´ë¯¸ ìì—°ë¡œê·¸ê°’
                
            return log_perplexity
            
        except Exception as e:
            logger.error(f"Error calculating log perplexity: {e}")
            return float('inf')
    
    def classify_sentence(self, log_ppl: float) -> Dict[str, Union[str, float]]:
        """ë¡œê·¸ perplexity ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ ë¶„ë¥˜"""
        if log_ppl == float('inf'):
            return {
                'classification': 'ERROR',
                'confidence': 0.0,
                'ai_suspicious': False
            }
        
        if log_ppl <= self.LOG_PPL_THRESHOLD:
            # AI ìƒì„± ì˜ì‹¬
            confidence = (self.LOG_PPL_THRESHOLD - log_ppl) / self.LOG_PPL_THRESHOLD
            confidence = max(0.0, min(1.0, confidence))
            
            return {
                'classification': 'AI_SUSPICIOUS',
                'confidence': confidence,
                'ai_suspicious': True
            }
        else:
            # ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥
            confidence = min(1.0, (log_ppl - self.LOG_PPL_THRESHOLD) / 2.0)
            
            return {
                'classification': 'NATURAL',
                'confidence': confidence,
                'ai_suspicious': False
            }
    
    def analyze_sentences(self, text: str) -> Dict:
        """ë¬¸ì¥ë³„ë¡œ ë¶„ì„í•˜ê³  AI ì˜ì‹¬ ë¬¸ì¥ë“¤ì„ ë¶„ë¥˜"""
        sentences = split_into_sentences(text)
        
        if not sentences:
            return {
                'ai_suspicious_sentences': [],
                'natural_sentences': [],
                'error_sentences': [],
                'overall_stats': {
                    'total_sentences': 0,
                    'ai_suspicious_count': 0,
                    'natural_count': 0,
                    'ai_ratio': 0.0
                }
            }
        
        ai_suspicious = []
        natural = []
        errors = []
        
        for i, sentence in enumerate(tqdm(sentences, desc="Analyzing sentences")):
            log_ppl = self.calculate_log_perplexity(sentence)
            classification = self.classify_sentence(log_ppl)
            
            sentence_data = {
                'text': sentence,
                'log_perplexity': log_ppl,
                'position': i,
                **classification
            }
            
            if classification['classification'] == 'AI_SUSPICIOUS':
                ai_suspicious.append(sentence_data)
            elif classification['classification'] == 'NATURAL':
                natural.append(sentence_data)
            else:
                errors.append(sentence_data)
        
        # AI ì˜ì‹¬ ë¬¸ì¥ë“¤ì„ confidence ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì˜ì‹¬ë„ë¶€í„°)
        ai_suspicious.sort(key=lambda x: x['confidence'], reverse=True)
        
        # í†µê³„ ê³„ì‚°
        total_count = len(sentences)
        ai_count = len(ai_suspicious)
        ai_ratio = ai_count / total_count if total_count > 0 else 0.0
        
        return {
            'ai_suspicious_sentences': ai_suspicious,
            'natural_sentences': natural,
            'error_sentences': errors,
            'overall_stats': {
                'total_sentences': total_count,
                'ai_suspicious_count': ai_count,
                'natural_count': len(natural),
                'error_count': len(errors),
                'ai_ratio': ai_ratio
            },
            'recommendations': self._generate_recommendations(ai_suspicious, ai_ratio)
        }
    
    def _generate_recommendations(self, ai_suspicious: List[Dict], ai_ratio: float) -> List[str]:
        """ìˆ˜ì • ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if ai_ratio >= 0.5:
            recommendations.append("âš ï¸  ì „ì²´ ë¬¸ì¥ì˜ 50% ì´ìƒì´ AI ìƒì„±ìœ¼ë¡œ ì˜ì‹¬ë©ë‹ˆë‹¤. ì „ë©´ ìˆ˜ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        elif ai_ratio >= 0.3:
            recommendations.append("âš ï¸  ìƒë‹¹ìˆ˜ ë¬¸ì¥ì´ AI ìƒì„±ìœ¼ë¡œ ì˜ì‹¬ë©ë‹ˆë‹¤. ì£¼ìš” ë¬¸ì¥ë“¤ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
        elif ai_ratio > 0:
            recommendations.append("âœ“ ì¼ë¶€ ë¬¸ì¥ë§Œ AI ìƒì„±ìœ¼ë¡œ ì˜ì‹¬ë©ë‹ˆë‹¤. í•´ë‹¹ ë¬¸ì¥ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            recommendations.append("âœ… AI ìƒì„±ì´ ì˜ì‹¬ë˜ëŠ” ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ë¬¸ì¥ë“¤ (confidence > 0.8) ì•Œë¦¼
        high_priority = [s for s in ai_suspicious if s['confidence'] > 0.8]
        if high_priority:
            positions = [str(s['position'] + 1) for s in high_priority[:3]]  # ìµœëŒ€ 3ê°œë§Œ
            recommendations.append(f"ğŸ”¥ ìš°ì„  ìˆ˜ì • í•„ìš” ë¬¸ì¥: {', '.join(positions)}ë²ˆ")
        
        return recommendations
    
    def analyze_batch(self, texts: List[str]) -> List[Dict]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ë¶„ì„"""
        results = []
        
        for i, text in enumerate(tqdm(texts, desc="Analyzing batch")):
            logger.info(f"Analyzing text {i+1}/{len(texts)}")
            result = self.analyze_sentences(text)
            result['text_id'] = i
            results.append(result)
        
        return results
    
    def get_model_info(self) -> Dict[str, Union[str, float]]:
        """í˜„ì¬ ì‚¬ìš©ì¤‘ì¸ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            'model_name': self.model_name,
            'device': str(self.model_manager.device),
            'max_length': self.max_length,
            'log_ppl_threshold': self.LOG_PPL_THRESHOLD
        }